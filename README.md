# A Neuro-Driven Mobile Robot Enhanced by LoRa and EEG Technology

## Project Overview

The **Neuro-Driven Mobile Robot** project represents a groundbreaking advancement in mobile robotics by integrating cognitive science, robotics, and long-range communication technologies. This system leverages a Brain-Computer Interface (BCI) to enable direct human-robot interaction based on cognitive states interpreted from EEG signals. 

The core components of the system include:
- **MindWave Headset:** Used to capture EEG signals from the user.
- **MATLAB:** Facilitates the processing and analysis of EEG data and acts as an interface between the BCI sensor and the laptop.
- **LoRa Technology:** Enables efficient and reliable long-range communication between the robot and the user interface.

The system allows users to control the robot's movements and actions using neuro-driven commands derived from real-time cognitive states. This integration offers significant advancements in how robots interact with human operators, making it applicable for various fields including exploration, surveillance, and assistance.

## Features

- **Brain-Computer Interface (BCI):** Provides intuitive and natural control by interpreting cognitive commands from EEG signals.
- **Long-Range Communication:** Uses LoRa technology for reliable data transfer over extended distances, overcoming limitations of traditional short-range communication.
- **Neuro-Driven Control:** Enhances the robot’s autonomy by allowing it to make decisions based on real-time cognitive data.
- **Real-Time Video Monitoring:** Provides live video feeds from the robot’s camera, allowing users to remotely monitor and control the robot’s environment.
- **Versatile Applications:** Suitable for exploration, surveillance, assistance, and other domains requiring advanced human-robot interaction.

## Advantages

- **Enhanced Human-Robot Interaction:** Directly interprets cognitive commands, facilitating more natural and intuitive control.
- **Extended Operational Range:** LoRa technology allows the robot to operate over long distances without the constraints of short-range communication.
- **Improved Autonomy:** The robot can navigate and interact autonomously based on cognitive inputs, enhancing its effectiveness in dynamic environments.
- **Enhanced Remote Monitoring:** Real-time video feed offers improved situational awareness for remote operations.
- **Versatile Applications:** Opens up new possibilities in various fields by combining cognitive science with robotics and communication technology.

## System Requirements

### Hardware Requirements

- **CPU Type:** Intel Pentium 4
- **Clock Speed:** 3.0 GHz
- **RAM Size:** 2 GB
- **Hard Disk Capacity:** 40 GB
- **Monitor:** 15-inch color monitor
- **Keyboard:** Internet keyboard
- **Microcontroller:** Required for controlling various components
- **BCI Sensor:** MindWave headset for EEG signal acquisition
- **LoRa Module:** For long-range communication
- **Motor Driver:** Controls the DC motors
- **DC Motor:** Powers the robot’s movement
- **Battery:** 9V battery for powering the robot

### Software Requirements

- **Operating System:** Windows OS
- **Programming Languages:** Embedded C, MATLAB
- **IDEs:** Visual Studio Code, Arduino IDE, MATLAB IDE
- **Applications:** Windows Application for interface and control

## Installation and Setup

1. **Install Required Software:**
   - Ensure that MATLAB, Visual Studio Code, and Arduino IDE are installed on your system.
   - Install any necessary libraries or packages for MATLAB and Arduino IDE.

2. **Setup Hardware Components:**
   - Connect the BCI sensor, LoRa module, motor driver, and other hardware components according to the project specifications.

3. **Run the System:**
   - Follow the detailed instructions and scripts provided in the repository to initialize and operate the system.

## Usage

1. **BCI Interface:** Wear the MindWave headset to start interpreting EEG signals.
2. **Control the Robot:** Use the neuro-driven commands derived from cognitive states to control the robot’s movements and actions.
3. **Monitor and Analyze:** Utilize the real-time video feed to monitor the robot’s surroundings and make adjustments as needed.

## Author

- **Akash R**  
